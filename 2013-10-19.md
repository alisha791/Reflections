###Week 7

On Tuesday, our class discussed the next assignment that's due. It was interesting to see how we can import real-time data into ipython notebook and then plot that data on a map. This assigment was suppose to be more approachable than the last but by Friday I was very confused and frustrated because I did not know how to use JSON or cache data, let alone what caching data really meant. My group met on Saturday to discuss the assignment in office hours with Aaron. Unfortunately, after a couple hours of working with Aaron and members of other groups, I was still unclear about the assignment. I understood what it meant to cache the data and that I needed to install panda in VM but I still could not read the new data using JSON. Our group decided that maybe it was best to use Aaron's original code and cache the data from the csv file. However, as we were leaving office hours, another student from our class came in and briefly showed us how he was able to use JSON. One of my group members who was also working on data curation decided to learn more about JSON and try again. She was successful and after looking at her code, I too have a better understanding of how JSON works. I'm sure this was an 'Aha' moment for her but it was also an 'Aha' moment for me because I could follow her code and I now have a better understanding of JSON. Meanwhile, I was working on caching the data. I realized that this was actually pretty simple. All I had to do was use to_csv('FileName') to save the data. A student from my horizontal group helped me use this function properly and pointed out that it would be a good idea to name the cached data with the date that it was cached. Using the datetime function, I was able to cache the data and give it a meaningful name. This is useful because if someone else wants to see the saved data, he/she will know exactly when the data was cached. At this point, I was able to cache the data and save it to my virtual machine. When I typed 'ls' in my Virtual Machine, I saw the file name listed but I did not know how to open it. After reading about git push and cd, I finally understood where that file was stored and how to access it. This was a big 'Aha' moment for me because I realized that I had been unaware of how git push worked for the past 7 weeks. I now know that you have to use git clone to access a specific repository in VM and then cd into that repository so that I can git push files there. In addition, I have to make sure to open ipython notebook while I am in that directory so that I can save the cached data there. To actually push the cached data into my repository I have to used git add, git commit, and git push. I am still having issues with merging the changes I make in my repo through github.com and the changes I make through my VM but hopefully after some more reading, I will be able to figure this out. Overall, this assignment was definitely more challenging than I expected, but I'm glad that everyone was willing to work collaboratively and help out. Now our group is just working on perfecting the visualization part of the assignment. 

On Thursday, Professor Stark came in to present. He discussed the ETAS model and the new goal of the class. Although there was a lot of statistics that I did not understand in his presentation, I hope that by the end of the semester I will have a better understanding of the different earthquake models and that we will be able to reach our goal. I think that our new goal is slighly more feasible than trying to find a relationship between earthquake and rainfall data so I am hopeful. It would very exciting to publish a paper as a class!
